#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\usepackage{listings,xcolor,courier,bookmark}
\usepackage{listingsutf8}
\definecolor{darkblue}{named}{blue}
\definecolor{darkred}{named}{red}
\definecolor{grau}{named}{gray}
\let\Righttorque\relax
\lstset{
captionpos=b,
commentstyle=\color[rgb]{0.133,0.545,0.133},
keywordstyle=\color{darkblue},
stringstyle=\color{darkred},
extendedchars=true,
basicstyle=\small\ttfamily,
showstringspaces=false,
tabsize=2,
numbers=left,
numberstyle=\tiny,
breakautoindent  = true,
breakindent      = 2em,
breaklines       = true,
postbreak        = ,
prebreak         = \raisebox{-.8ex}[0ex][0ex]{\Righttorque},
showspaces=false, 
showtabs=false, 
showstringspaces=false,
language=VHDL,
frame=single,
morecomment=[s]{--}
}


\renewcommand*{\lstlistingname}{Codice Componente}


\usepackage{fancyhdr}
\pagestyle{fancy}

\fancyhead{} 
\fancyfoot{} 

\fancyhead[RO,LE]{\bfseries \leftmark}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[LO,CE]{Tesina in ASE: Architetture dei Sistemi di Elaborazione}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\date{}
\cfoot{}
\usepackage{eso-pic,graphicx}
\makeatletter
\newcommand\BackgroundPicture[2]{
\setlength{\unitlength}{1pt}
\put(0,\strip@pt\paperheight){
\parbox[t][\paperheight]{\paperwidth}{
\vfill
\centering\includegraphics[angle=#2]{#1}
\vfill
}
}
}
\makeatother
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language italian
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2.5cm
\rightmargin 2cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
In tale capitolo è riportata l'architettura con il relativo stack tecnologico
 utilizzato ai fini della realizzazione del progetto.
 In paricolare sono stati utilizzati i seguenti componenti:
\end_layout

\begin_layout Itemize
Microsoft Azure: è una piattaforma cloud pubblica di Microsoft, che offre
 servizi di cloud computing.
\end_layout

\begin_layout Itemize
MongoDB: è un DBMS non relazionale (NoSQL), orientato ai documenti.
\end_layout

\begin_layout Itemize
Apache Spark: è un framework open source per il calcolo distribuito.
\end_layout

\begin_layout Section
Microsoft Azure
\end_layout

\begin_layout Standard
Come detto precedentemente Azure è una piattaforma cloud pubblica di Microsoft,
 che offre servizi di cloud computing.
 Tramite essa vengono erogati servizi appartenenti a diverse categorie quali:
 risorse di elaborazione, archiviazione e memorizzazione dati, trasmissione
 dati e interconnessione di reti, analisi, intelligence, monitoraggio e
 gestione, nonchè servizi per lo sviluppo di applicazioni.
 In particolare i servizi messi a disposizione possono essere classificati
 in tre specifiche aree, a seconda della modalità di erogazione adottata:
 
\end_layout

\begin_layout Itemize
Infrastructure-as-a-Service (IaaS)
\end_layout

\begin_layout Itemize
Platform-as-a-Service (PaaS)
\end_layout

\begin_layout Itemize
Software-as-a-Service (SaaS)
\end_layout

\begin_layout Standard
Ciascun servizio erogato prevede un pagamento in base al consumo e la metodologi
a con cui ne viene determinato il costo è specifica per il servizio stesso.
 Ai fini del nostro progetto si è sfruttata tale piattaforma per usufruire
 di una macchina virtuale con le seguenti caratteristiche:
\end_layout

\begin_layout Itemize
Sistema operativo: Linux Ubuntu 17.04
\end_layout

\begin_layout Itemize
8 core , 16GB di memoria
\end_layout

\begin_layout Itemize
Processore Intel Xeon E5
\end_layout

\begin_layout Section
MongoDB
\end_layout

\begin_layout Standard
MongoDB è un database NoSQL orientato ai documenti, che nasce nel 2007 in
 California come servizio da utilizzare nell’ambito di un progetto più ampio,
 ma che presto è diventato un prodotto indipendente ed open-source.
 Esso memorizza i documenti in JSON, formato basato su JavaScript e più
 semplice di XML, ma comunque dotato di una buona espressività.
 Esso quindi si allontana dalla struttura tradizionale basata su tabelle
 dei database relazionali in favore di documenti in stile JSON con schema
 dinamico, rendendo l'integrazione di dati di alcuni tipi di applicazioni
 più facile e veloce.
 Come detto precedentemente, mongoDB è un database orientato ai documenti,
 ma cosa è un documento? Un docuemnto è fondamentalmente un albero che può
 contenere molti dati, anche annidati.
 I documenti sono raggruppati in collezioni che possono essere anche eterogenee.
 Ciò significa che non c'è uno schema fisso per i documenti.
 Tra le collezioni non ci sono relazioni o legami garantiti da MongoDB:
 in altre parole, non esiste un concetto analogo al vincolo di integrità
 referenziale.
\end_layout

\begin_layout Standard
Modello logico a parte, le caratteristiche chiave di MongoDB sono:
\end_layout

\begin_layout Itemize
Query ad hoc:
\end_layout

\begin_deeper
\begin_layout Itemize
MongoDB supporta ricerche per campi, intervalli e regular expression.
 Le query possono restituire campi specifici del documento e anche includere
 funzioni definite dall'utente in JavaScript.
\end_layout

\end_deeper
\begin_layout Itemize
Indicizzazione:
\end_layout

\begin_deeper
\begin_layout Itemize
qualunque campo in MongoDB può essere indicizzato (gli indici in MongoDB
 sono concettualmente similari a quelli dei tradizionali RDBMS).
 Sono disponibili anche indici secondari, indici unici, indici sparsi, indici
 geospaziali e indici full text.
\end_layout

\end_deeper
\begin_layout Itemize
Alta Affidabilità:
\end_layout

\begin_deeper
\begin_layout Itemize
MongoDB fornisce alta disponibilità e aumento del carico gestito attraverso
 i replica set.
 Un replica set consiste in due o più copie dei dati.
 Ogni replica può avere il ruolo di copia primaria o secondaria in qualunque
 momento.
 La replica primaria effettua tutte le scritture e le letture.
 Le repliche secondarie mantengono una copia dei dati della replica primaria
 attraverso un meccanismo di replicazione incluso nel prodotto.
 Quando una replica primaria fallisce, il replica set inizia automaticamente
 un processo di elezione per determinare quale replica secondaria deve diventare
 primaria.
 Le copie secondarie possono anche effettuare letture, con dati eventualmente
 consistenti di default.
\end_layout

\end_deeper
\begin_layout Itemize
Sharding e bilanciamento dei dati: 
\end_layout

\begin_deeper
\begin_layout Itemize
MongoDB scala orizzontalmente usando lo sharding.
 L'utente deve scegliere una chiave di sharding, che determina come i dati
 di una collection saranno distribuiti tra i vari nodi.
 I dati sono divisi in intervalli (basati sulla chiave di shard) e distribuiti
 su molteplici shard (uno shard è un replica set, quindi con una replica
 primaria e due o più repliche secondarie).
\end_layout

\begin_layout Itemize
MongoDB include un meccanismo di bilanciamento dei dati, spostando gli intervall
i di dati da uno shard troppo carico ad uno shard meno carico, in modo da
 bilanciare la distribuzione dei dati all'interno del cluster.
\end_layout

\end_deeper
\begin_layout Itemize
File Storage:
\end_layout

\begin_deeper
\begin_layout Itemize
MongoDB può essere usato anche come un file system, traendo vantaggio dalla
 caratteristiche di replicazione e di bilanciamento su più server per memorizzar
e file, anche di grandi dimensioni.
\end_layout

\begin_layout Itemize
Questa funzione, chiamata GridFS, è inclusa nei drivers di MongoDB e disponibile
 facilmente per tantissimi linguaggi di sviluppo.
 MongoDB espone delle funzioni per la manipolazione dei file.
 GridFS è usato, ad esempio, nei plugin di NGINX e lighttpd.
 Invece di memorizzare il file in un singolo documento, GridFS divide il
 file in tante parti più piccole, chiamate chunks, e memorizza ognuno di
 questi chunk in un documento separato.
\end_layout

\begin_layout Itemize
Ai file possono essere associati dei metadati, su cui è possibile anche
 creare degli indici full-text.
\end_layout

\end_deeper
\begin_layout Itemize
Aggregazione:
\end_layout

\begin_deeper
\begin_layout Itemize
MongoDB supporta due modalità di aggregazione dei dati: il MapReduce e l'Aggregr
ation Framework.
 Quest'ultimo lavora come una pipeline e permette di ottenere risultati
 molto più rapidamente del MapReduce grazie all'implementazione in C++.
\end_layout

\end_deeper
\begin_layout Itemize
Capped Collection: 
\end_layout

\begin_deeper
\begin_layout Itemize
MongoDB supporta collection a dimensioni fisse chiamate capped collection.
 Questo tipo di collection mantengono l'ordine di inserimento e una volta
 raggiunta la dimensione definita, si comportano come code circolari.
\end_layout

\end_deeper
\begin_layout Standard
Di seguito viene mostrata l'architettura relativa a mongoDB:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/MongoDB-Architecture.jpg
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
MongoDB Architecture
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Spark
\end_layout

\begin_layout Standard
Apache Spark è un framework open source per il calcolo distribuito sviluppato
 dall'AMPlab della Università della California e successivamente donato
 alla Apache Software Foundation.
 A differenza del paradigma MapReduce, basato sul disco a due livelli di
 Hadoop, le primitive "in-memory" multilivello di Spark forniscono prestazioni
 fino a 100 volte migliori per talune applicazioni.
 Ciò permette ai programmi utente di caricare dati in un gruppo di memorie
 e interrogarlo ripetutamente.
 Spark richiede un gestore di cluster e un sistema di archiviazione distribuita.
 Per il primo supporta nativamente un cluster Spark ma anche Hadoop YARN,
 per il secondo Spark può interfacciarsi con Hadoop Distributed File System
 (HDFS), Apache Cassandra, Amazon S3, ma anche soluzioni personalizzabili.
 Spark supporta anche soluzioni pseudo-distribuite in modalità locale, usate
 di solito per lo sviluppo o scopo di test, dove l'archiviazione distribuita
 non è richiesta e si usa il file system locale; in tale scenario, Spark
 è eseguito su una macchina singola.
 L’architettura di Spark si compone di un master scheduler e di tanti worker
 che eseguono il calcolo distribuito, quindi secondo quello che è lo standard
 architetturare dei sistemi distribuiti.
 Ovviamente gli sviluppatori di Spark fanno notare nel loro paper che Spark
 è stato pensato per dare il meglio nelle elaborazioni batch, mentre non
 funziona in maniera performante in sistemi distribuiti che richiedono frequenti
 update granulari sui set di dati archiviati.
 In quel caso, meglio evitare di usare Spark o Hadoop e invece usare un
 normale sistema di database o un sistema di distributed shared memory,
 che sono invece pensati per questo.
 Di seguito è riportata l'architettura relativa al framework Apache Spark:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/SparkArchitecture.JPG
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Spark Architecture
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_body
\end_document
